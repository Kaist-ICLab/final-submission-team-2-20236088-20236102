{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZBFzjClURz"
      },
      "source": [
        "# IoT Data Science Project\n",
        "\n",
        "This notebook demonstrates our process of training a model using TensorFlow and converting it for use with TensorFlow Lite for Microcontrollers. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UQblnrLd_ET"
      },
      "source": [
        "## Configure Defaults"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PYwRFppd-WB"
      },
      "source": [
        "# Define paths to model files\n",
        "import os\n",
        "MODELS_DIR = 'models/'\n",
        "try:\n",
        "  os.mkdir(MODELS_DIR)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "MODEL_TF = MODELS_DIR + 'model.pb'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh4AXGuHWeu1"
      },
      "source": [
        "## Setup Environment\n",
        "\n",
        "Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "143e5d57-e0d7-48f0-ebec-e5b5763f4760",
        "id": "cr1VLfotanf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%pip install tensorflow pandas numpy plotly\n",
        "!apt install -y xxd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.13.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xxd is already the newest version (2:8.1.2269-1ubuntu5.14).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rLYpvtg9P4o"
      },
      "source": [
        "Set Seed for Repeatable Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIH9NN1c9PJn"
      },
      "source": [
        "# Set a \"seed\" value, so we get the same random numbers each time we run this\n",
        "# notebook for reproducible results.\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "np.random.seed(1) # numpy seed\n",
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1) # tensorflow global random seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx9lOPWh9grN"
      },
      "source": [
        "Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53PBJBv1jEtJ"
      },
      "source": [
        "# Keras is TensorFlow's high-level API for deep learning\n",
        "from tensorflow import keras\n",
        "# Plotly for graphing library\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "# Math is Python's math library\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-PuBEb6CMeo"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "assert(\"input.npy\" in uploaded.keys())\n",
        "assert(\"output.npy\" in uploaded.keys())"
      ],
      "metadata": {
        "id": "Voe9E-pr4_76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "84b3e4fb-b4ff-4434-ae27-9506bb507fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12135197-8da0-4543-9aea-3698b2686772\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12135197-8da0-4543-9aea-3698b2686772\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving output.npy to output.npy\n",
            "Saving input.npy to input.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_values = np.load(\"input.npy\")\n",
        "y_values = np.load(\"output.npy\")\n",
        "\n",
        "print(x_values.shape)\n",
        "print(y_values.shape)\n",
        "assert(x_values.shape[0] == y_values.shape[0])\n",
        "\n",
        "print(x_values.shape,x_values[0])\n",
        "\n",
        "SAMPLES = x_values.shape[0]\n",
        "INPUT_SIZE = x_values.shape[1]\n",
        "OUTPUT_SIZE = y_values.shape[1]"
      ],
      "metadata": {
        "id": "icFj-jfn6ohU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016f2cef-e050-4bdc-ad89-85ed2aadc208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8992, 20)\n",
            "(8992, 2)\n",
            "(8992, 20) [0.99 0.98 0.99 0.99 0.99 0.99 0.98 0.98 0.99 0.99 0.98 0.98 0.99 0.99\n",
            " 0.99 0.99 0.99 0.99 0.99 0.99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x_values = scaler.fit_transform(x_values)"
      ],
      "metadata": {
        "id": "t2GAmL5KHJTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We print the attributes of the scaler to easily paste them into the arduino code."
      ],
      "metadata": {
        "id": "xXct-gLTwfsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*scaler.mean_, sep = ', ')\n",
        "print(*scaler.scale_, sep = ', ')"
      ],
      "metadata": {
        "id": "1LrkXuRbKGBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ac3992-5590-428e-8c0b-8199346e7038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.002244217081706, 0.9969739768681863, 0.9780427046261917, 0.9774699733094625, 0.9885242437720999, 0.9912844750888308, 0.9855393683272579, 0.9825700622774357, 0.9850900800710304, 0.98709630782904, 0.9885487099642675, 0.9860542704624866, 0.9812700177934556, 0.9842415480425621, 0.9943527580069715, 0.9891570284696034, 0.9749644128112522, 0.9777680160141146, 1.0058463078290605, 1.0034842081849311\n",
            "0.057016487613638034, 0.043192446111424754, 0.04688370512457536, 0.04284471606258267, 0.039743557294276026, 0.03810319196110418, 0.0391970454251776, 0.03818838200425476, 0.036293961922855646, 0.03904424872185462, 0.04310507194035918, 0.03947357881955382, 0.03882232144002737, 0.04378275001672496, 0.049458627264599826, 0.04295937918789064, 0.042593299062306945, 0.05143179509233413, 0.0602858327289839, 0.055622827997059886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up8Xk_pMH4Rt"
      },
      "source": [
        "### 3. Split the Data\n",
        "We will be using our data to train our model.\n",
        "\n",
        "The data is split as follows:\n",
        "  1. Training: 60%\n",
        "  2. Validation: 20%\n",
        "  3. Testing: 20% \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNYko5L1keqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c549a2-05b3-4d03-d3ce-1bc5792c90ed"
      },
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "shuffle = np.arange(x_values.shape[0])\n",
        "print(shuffle)\n",
        "np.random.shuffle(shuffle)\n",
        "print(shuffle)\n",
        "x_values = x_values[shuffle]\n",
        "y_values = y_values[shuffle]\n",
        "print(x_values.shape)\n",
        "print(y_values.shape)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.shape[0] + x_validate.shape[0] + x_test.shape[0]) ==  SAMPLES\n",
        "\n",
        "print(\"Class balance in train:\", np.sum(y_train, axis=0))\n",
        "print(\"Class balance in test:\", np.sum(y_test, axis=0))\n",
        "print(\"Class balance in validate:\", np.sum(y_validate, axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    1    2 ... 8989 8990 8991]\n",
            "[7885 8231 7798 ...  905 5192  235]\n",
            "(8992, 20)\n",
            "(8992, 2)\n",
            "Class balance in train: [2678. 2717.]\n",
            "Class balance in test: [932. 866.]\n",
            "Class balance in validate: [886. 913.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfdelu1TmgPk"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5McVnHmNiDw"
      },
      "source": [
        "### 1. Design the Model\n",
        "We're going to build a simple neural network model that will take 20 input values (a time series of values) and use it to classify a tap or not a tap. This type of problem is called a classification. It will use _layers_ of _neurons_ to attempt to learn any patterns underlying the training data, so it can make classifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD60bE8cXQId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16dc5b5f-bafb-4be4-bec2-350779eab734"
      },
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "model_1 = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 8 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model_1.add(keras.layers.Dense(8, activation='relu', input_shape=(INPUT_SIZE,)))\n",
        "model_1.add(keras.layers.Dense(OUTPUT_SIZE, activation='softmax'))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for binary classification\n",
        "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mae'])\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 8)                 168       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 186\n",
            "Trainable params: 186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0idLyRLQeGj"
      },
      "source": [
        "### 2. Train the Model\n",
        "Once we've defined the model, we can use our data to _train_ it. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8hQKr4cVOdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b6a6b1-e3ff-44fc-80db-aa360d1dd505"
      },
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "history_1 = model_1.fit(x_train, y_train, epochs=150, batch_size=64,\n",
        "                    validation_data=(x_validate, y_validate))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "85/85 [==============================] - 1s 5ms/step - loss: 0.6574 - mae: 0.4500 - val_loss: 0.5835 - val_mae: 0.3837\n",
            "Epoch 2/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5375 - mae: 0.3431 - val_loss: 0.4858 - val_mae: 0.3008\n",
            "Epoch 3/150\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.4495 - mae: 0.2704 - val_loss: 0.4070 - val_mae: 0.2362\n",
            "Epoch 4/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.3741 - mae: 0.2070 - val_loss: 0.3364 - val_mae: 0.1759\n",
            "Epoch 5/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.3044 - mae: 0.1471 - val_loss: 0.2711 - val_mae: 0.1210\n",
            "Epoch 6/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.2431 - mae: 0.0988 - val_loss: 0.2170 - val_mae: 0.0821\n",
            "Epoch 7/150\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 0.1943 - mae: 0.0669 - val_loss: 0.1753 - val_mae: 0.0580\n",
            "Epoch 8/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 0.1580 - mae: 0.0481 - val_loss: 0.1444 - val_mae: 0.0435\n",
            "Epoch 9/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.1309 - mae: 0.0368 - val_loss: 0.1211 - val_mae: 0.0342\n",
            "Epoch 10/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.1106 - mae: 0.0295 - val_loss: 0.1034 - val_mae: 0.0282\n",
            "Epoch 11/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0950 - mae: 0.0246 - val_loss: 0.0893 - val_mae: 0.0234\n",
            "Epoch 12/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 0.0826 - mae: 0.0208 - val_loss: 0.0779 - val_mae: 0.0198\n",
            "Epoch 13/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 0.0724 - mae: 0.0180 - val_loss: 0.0685 - val_mae: 0.0168\n",
            "Epoch 14/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0639 - mae: 0.0154 - val_loss: 0.0607 - val_mae: 0.0145\n",
            "Epoch 15/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0568 - mae: 0.0136 - val_loss: 0.0542 - val_mae: 0.0127\n",
            "Epoch 16/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0507 - mae: 0.0121 - val_loss: 0.0486 - val_mae: 0.0111\n",
            "Epoch 17/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0456 - mae: 0.0107 - val_loss: 0.0437 - val_mae: 0.0096\n",
            "Epoch 18/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0412 - mae: 0.0094 - val_loss: 0.0394 - val_mae: 0.0086\n",
            "Epoch 19/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.0374 - mae: 0.0086 - val_loss: 0.0358 - val_mae: 0.0075\n",
            "Epoch 20/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0341 - mae: 0.0076 - val_loss: 0.0325 - val_mae: 0.0067\n",
            "Epoch 21/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0312 - mae: 0.0070 - val_loss: 0.0297 - val_mae: 0.0062\n",
            "Epoch 22/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0287 - mae: 0.0063 - val_loss: 0.0273 - val_mae: 0.0057\n",
            "Epoch 23/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0265 - mae: 0.0059 - val_loss: 0.0250 - val_mae: 0.0051\n",
            "Epoch 24/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.0244 - mae: 0.0054 - val_loss: 0.0230 - val_mae: 0.0048\n",
            "Epoch 25/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0226 - mae: 0.0049 - val_loss: 0.0213 - val_mae: 0.0043\n",
            "Epoch 26/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0210 - mae: 0.0045 - val_loss: 0.0197 - val_mae: 0.0039\n",
            "Epoch 27/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0195 - mae: 0.0041 - val_loss: 0.0182 - val_mae: 0.0037\n",
            "Epoch 28/150\n",
            "85/85 [==============================] - 1s 10ms/step - loss: 0.0182 - mae: 0.0038 - val_loss: 0.0170 - val_mae: 0.0035\n",
            "Epoch 29/150\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.0170 - mae: 0.0036 - val_loss: 0.0157 - val_mae: 0.0031\n",
            "Epoch 30/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0159 - mae: 0.0032 - val_loss: 0.0147 - val_mae: 0.0028\n",
            "Epoch 31/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0148 - mae: 0.0030 - val_loss: 0.0137 - val_mae: 0.0026\n",
            "Epoch 32/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0139 - mae: 0.0028 - val_loss: 0.0128 - val_mae: 0.0024\n",
            "Epoch 33/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0131 - mae: 0.0025 - val_loss: 0.0120 - val_mae: 0.0022\n",
            "Epoch 34/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0123 - mae: 0.0024 - val_loss: 0.0113 - val_mae: 0.0021\n",
            "Epoch 35/150\n",
            "85/85 [==============================] - 1s 10ms/step - loss: 0.0116 - mae: 0.0022 - val_loss: 0.0106 - val_mae: 0.0020\n",
            "Epoch 36/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0109 - mae: 0.0021 - val_loss: 0.0100 - val_mae: 0.0018\n",
            "Epoch 37/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0103 - mae: 0.0019 - val_loss: 0.0094 - val_mae: 0.0017\n",
            "Epoch 38/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0097 - mae: 0.0018 - val_loss: 0.0089 - val_mae: 0.0016\n",
            "Epoch 39/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0092 - mae: 0.0017 - val_loss: 0.0084 - val_mae: 0.0015\n",
            "Epoch 40/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0086 - mae: 0.0016 - val_loss: 0.0080 - val_mae: 0.0014\n",
            "Epoch 41/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0082 - mae: 0.0015 - val_loss: 0.0076 - val_mae: 0.0013\n",
            "Epoch 42/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0077 - mae: 0.0014 - val_loss: 0.0072 - val_mae: 0.0012\n",
            "Epoch 43/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0073 - mae: 0.0013 - val_loss: 0.0068 - val_mae: 0.0012\n",
            "Epoch 44/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0069 - mae: 0.0013 - val_loss: 0.0065 - val_mae: 0.0011\n",
            "Epoch 45/150\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.0065 - mae: 0.0012 - val_loss: 0.0061 - val_mae: 0.0011\n",
            "Epoch 46/150\n",
            "85/85 [==============================] - 1s 10ms/step - loss: 0.0062 - mae: 0.0011 - val_loss: 0.0059 - val_mae: 0.0010\n",
            "Epoch 47/150\n",
            "85/85 [==============================] - 1s 13ms/step - loss: 0.0059 - mae: 0.0011 - val_loss: 0.0056 - val_mae: 9.5960e-04\n",
            "Epoch 48/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0056 - mae: 9.9812e-04 - val_loss: 0.0053 - val_mae: 8.9828e-04\n",
            "Epoch 49/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0053 - mae: 9.5061e-04 - val_loss: 0.0051 - val_mae: 8.7094e-04\n",
            "Epoch 50/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0050 - mae: 7.8413e-04 - val_loss: 0.0049 - val_mae: 7.7976e-04\n",
            "Epoch 51/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0047 - mae: 8.0827e-04 - val_loss: 0.0046 - val_mae: 7.5566e-04\n",
            "Epoch 52/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0045 - mae: 7.3906e-04 - val_loss: 0.0044 - val_mae: 7.1950e-04\n",
            "Epoch 53/150\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.0043 - mae: 6.6881e-04 - val_loss: 0.0042 - val_mae: 7.0334e-04\n",
            "Epoch 54/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0041 - mae: 6.5683e-04 - val_loss: 0.0040 - val_mae: 6.6390e-04\n",
            "Epoch 55/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0039 - mae: 6.0206e-04 - val_loss: 0.0038 - val_mae: 6.3278e-04\n",
            "Epoch 56/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0037 - mae: 5.5515e-04 - val_loss: 0.0036 - val_mae: 5.8238e-04\n",
            "Epoch 57/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0035 - mae: 5.1315e-04 - val_loss: 0.0035 - val_mae: 5.3294e-04\n",
            "Epoch 58/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0033 - mae: 4.4971e-04 - val_loss: 0.0033 - val_mae: 5.1142e-04\n",
            "Epoch 59/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0031 - mae: 4.0762e-04 - val_loss: 0.0032 - val_mae: 4.8919e-04\n",
            "Epoch 60/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.0030 - mae: 4.0510e-04 - val_loss: 0.0030 - val_mae: 4.5335e-04\n",
            "Epoch 61/150\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.0028 - mae: 3.6133e-04 - val_loss: 0.0029 - val_mae: 4.2643e-04\n",
            "Epoch 62/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 2.9370e-04 - val_loss: 0.0027 - val_mae: 3.5519e-04\n",
            "Epoch 63/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.0026 - mae: 3.2247e-04 - val_loss: 0.0026 - val_mae: 3.6436e-04\n",
            "Epoch 64/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.0024 - mae: 2.6704e-04 - val_loss: 0.0025 - val_mae: 3.0971e-04\n",
            "Epoch 65/150\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 2.4869e-04 - val_loss: 0.0024 - val_mae: 3.1545e-04\n",
            "Epoch 66/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.0022 - mae: 2.1303e-04 - val_loss: 0.0023 - val_mae: 2.7920e-04\n",
            "Epoch 67/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 1.9306e-04 - val_loss: 0.0022 - val_mae: 2.7002e-04\n",
            "Epoch 68/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 1.8457e-04 - val_loss: 0.0021 - val_mae: 2.5031e-04\n",
            "Epoch 69/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 1.6947e-04 - val_loss: 0.0020 - val_mae: 2.3573e-04\n",
            "Epoch 70/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 1.4725e-04 - val_loss: 0.0019 - val_mae: 2.2530e-04\n",
            "Epoch 71/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 1.3884e-04 - val_loss: 0.0018 - val_mae: 2.0481e-04\n",
            "Epoch 72/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 1.3447e-04 - val_loss: 0.0017 - val_mae: 1.9468e-04\n",
            "Epoch 73/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 1.1694e-04 - val_loss: 0.0017 - val_mae: 1.7146e-04\n",
            "Epoch 74/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 1.0214e-04 - val_loss: 0.0016 - val_mae: 1.7170e-04\n",
            "Epoch 75/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 9.8991e-05 - val_loss: 0.0015 - val_mae: 1.6106e-04\n",
            "Epoch 76/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 9.6452e-05 - val_loss: 0.0015 - val_mae: 1.5554e-04\n",
            "Epoch 77/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 7.9838e-05 - val_loss: 0.0014 - val_mae: 1.3680e-04\n",
            "Epoch 78/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 8.3401e-05 - val_loss: 0.0013 - val_mae: 1.2461e-04\n",
            "Epoch 79/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 6.9885e-05 - val_loss: 0.0013 - val_mae: 1.2794e-04\n",
            "Epoch 80/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 6.5414e-05 - val_loss: 0.0012 - val_mae: 1.1026e-04\n",
            "Epoch 81/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 5.4926e-05 - val_loss: 0.0012 - val_mae: 1.0117e-04\n",
            "Epoch 82/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 5.2986e-05 - val_loss: 0.0011 - val_mae: 9.7622e-05\n",
            "Epoch 83/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 9.9289e-04 - mae: 4.9390e-05 - val_loss: 0.0011 - val_mae: 8.6474e-05\n",
            "Epoch 84/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 9.4814e-04 - mae: 4.3609e-05 - val_loss: 0.0010 - val_mae: 8.1818e-05\n",
            "Epoch 85/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 9.0631e-04 - mae: 4.1456e-05 - val_loss: 0.0010 - val_mae: 7.6336e-05\n",
            "Epoch 86/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 8.6348e-04 - mae: 3.6922e-05 - val_loss: 9.6116e-04 - val_mae: 7.3207e-05\n",
            "Epoch 87/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 8.2483e-04 - mae: 3.4727e-05 - val_loss: 9.2362e-04 - val_mae: 6.9653e-05\n",
            "Epoch 88/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 7.8989e-04 - mae: 3.1612e-05 - val_loss: 8.8128e-04 - val_mae: 6.2395e-05\n",
            "Epoch 89/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 7.5649e-04 - mae: 2.9825e-05 - val_loss: 8.4367e-04 - val_mae: 5.6157e-05\n",
            "Epoch 90/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 7.1924e-04 - mae: 2.4274e-05 - val_loss: 8.1155e-04 - val_mae: 5.5239e-05\n",
            "Epoch 91/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 6.9038e-04 - mae: 2.5661e-05 - val_loss: 7.8051e-04 - val_mae: 5.1190e-05\n",
            "Epoch 92/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 6.5661e-04 - mae: 2.0738e-05 - val_loss: 7.5356e-04 - val_mae: 5.0458e-05\n",
            "Epoch 93/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 6.2985e-04 - mae: 1.9920e-05 - val_loss: 7.2114e-04 - val_mae: 4.6296e-05\n",
            "Epoch 94/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 6.0258e-04 - mae: 1.9387e-05 - val_loss: 6.9317e-04 - val_mae: 4.4611e-05\n",
            "Epoch 95/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 5.7421e-04 - mae: 1.6310e-05 - val_loss: 6.6737e-04 - val_mae: 3.7462e-05\n",
            "Epoch 96/150\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 5.4950e-04 - mae: 1.5430e-05 - val_loss: 6.4149e-04 - val_mae: 3.6462e-05\n",
            "Epoch 97/150\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 5.2422e-04 - mae: 1.3513e-05 - val_loss: 6.1661e-04 - val_mae: 3.5486e-05\n",
            "Epoch 98/150\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 5.0267e-04 - mae: 1.3664e-05 - val_loss: 5.9096e-04 - val_mae: 3.2504e-05\n",
            "Epoch 99/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 4.7995e-04 - mae: 1.0461e-05 - val_loss: 5.6979e-04 - val_mae: 3.1570e-05\n",
            "Epoch 100/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 4.5955e-04 - mae: 1.0664e-05 - val_loss: 5.4927e-04 - val_mae: 3.1621e-05\n",
            "Epoch 101/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 4.3921e-04 - mae: 9.6365e-06 - val_loss: 5.2912e-04 - val_mae: 2.8970e-05\n",
            "Epoch 102/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 4.2062e-04 - mae: 8.7209e-06 - val_loss: 5.1227e-04 - val_mae: 2.9122e-05\n",
            "Epoch 103/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 4.0197e-04 - mae: 7.9962e-06 - val_loss: 4.8964e-04 - val_mae: 2.6232e-05\n",
            "Epoch 104/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 3.8690e-04 - mae: 8.6758e-06 - val_loss: 4.7945e-04 - val_mae: 2.8442e-05\n",
            "Epoch 105/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 3.7010e-04 - mae: 7.0358e-06 - val_loss: 4.5461e-04 - val_mae: 2.2945e-05\n",
            "Epoch 106/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 3.5169e-04 - mae: 5.7235e-06 - val_loss: 4.3989e-04 - val_mae: 2.2770e-05\n",
            "Epoch 107/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 3.3756e-04 - mae: 6.2585e-06 - val_loss: 4.2357e-04 - val_mae: 2.1648e-05\n",
            "Epoch 108/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 3.2340e-04 - mae: 5.0628e-06 - val_loss: 4.0751e-04 - val_mae: 2.0215e-05\n",
            "Epoch 109/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 3.0892e-04 - mae: 4.3878e-06 - val_loss: 3.9375e-04 - val_mae: 2.0073e-05\n",
            "Epoch 110/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.9616e-04 - mae: 4.5410e-06 - val_loss: 3.7865e-04 - val_mae: 1.8746e-05\n",
            "Epoch 111/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.8412e-04 - mae: 4.6494e-06 - val_loss: 3.6762e-04 - val_mae: 1.8569e-05\n",
            "Epoch 112/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.7129e-04 - mae: 3.6579e-06 - val_loss: 3.5283e-04 - val_mae: 1.7548e-05\n",
            "Epoch 113/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.5956e-04 - mae: 3.3392e-06 - val_loss: 3.4180e-04 - val_mae: 1.6932e-05\n",
            "Epoch 114/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.4908e-04 - mae: 3.3880e-06 - val_loss: 3.2860e-04 - val_mae: 1.5564e-05\n",
            "Epoch 115/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.3822e-04 - mae: 2.6101e-06 - val_loss: 3.1777e-04 - val_mae: 1.5122e-05\n",
            "Epoch 116/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.2801e-04 - mae: 2.6962e-06 - val_loss: 3.0905e-04 - val_mae: 1.5358e-05\n",
            "Epoch 117/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.1925e-04 - mae: 2.4782e-06 - val_loss: 2.9821e-04 - val_mae: 1.4351e-05\n",
            "Epoch 118/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.0999e-04 - mae: 2.3571e-06 - val_loss: 2.8495e-04 - val_mae: 1.2830e-05\n",
            "Epoch 119/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2.0083e-04 - mae: 2.2445e-06 - val_loss: 2.7307e-04 - val_mae: 1.1612e-05\n",
            "Epoch 120/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.9190e-04 - mae: 1.8339e-06 - val_loss: 2.6756e-04 - val_mae: 1.2022e-05\n",
            "Epoch 121/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.8349e-04 - mae: 1.5958e-06 - val_loss: 2.5738e-04 - val_mae: 1.1603e-05\n",
            "Epoch 122/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.7562e-04 - mae: 1.3547e-06 - val_loss: 2.4687e-04 - val_mae: 1.0121e-05\n",
            "Epoch 123/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.6897e-04 - mae: 1.5896e-06 - val_loss: 2.3853e-04 - val_mae: 9.8665e-06\n",
            "Epoch 124/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.6155e-04 - mae: 1.3489e-06 - val_loss: 2.2891e-04 - val_mae: 9.0382e-06\n",
            "Epoch 125/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.5435e-04 - mae: 9.5600e-07 - val_loss: 2.2390e-04 - val_mae: 9.1340e-06\n",
            "Epoch 126/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.4764e-04 - mae: 1.0088e-06 - val_loss: 2.1841e-04 - val_mae: 9.2319e-06\n",
            "Epoch 127/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.4136e-04 - mae: 9.8215e-07 - val_loss: 2.1102e-04 - val_mae: 8.9369e-06\n",
            "Epoch 128/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 1.3535e-04 - mae: 8.4643e-07 - val_loss: 2.0684e-04 - val_mae: 9.5345e-06\n",
            "Epoch 129/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 1.2977e-04 - mae: 7.8761e-07 - val_loss: 1.9873e-04 - val_mae: 8.7637e-06\n",
            "Epoch 130/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 1.2466e-04 - mae: 8.4121e-07 - val_loss: 1.9263e-04 - val_mae: 8.3140e-06\n",
            "Epoch 131/150\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 1.1944e-04 - mae: 6.8283e-07 - val_loss: 1.8700e-04 - val_mae: 8.1833e-06\n",
            "Epoch 132/150\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 1.1432e-04 - mae: 6.4503e-07 - val_loss: 1.8090e-04 - val_mae: 7.8597e-06\n",
            "Epoch 133/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.0962e-04 - mae: 6.0030e-07 - val_loss: 1.7226e-04 - val_mae: 7.0888e-06\n",
            "Epoch 134/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.0500e-04 - mae: 4.9047e-07 - val_loss: 1.6836e-04 - val_mae: 7.0981e-06\n",
            "Epoch 135/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1.0079e-04 - mae: 5.0607e-07 - val_loss: 1.6539e-04 - val_mae: 7.4251e-06\n",
            "Epoch 136/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 9.6536e-05 - mae: 4.5052e-07 - val_loss: 1.5601e-04 - val_mae: 5.9011e-06\n",
            "Epoch 137/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 9.2589e-05 - mae: 4.2629e-07 - val_loss: 1.5294e-04 - val_mae: 6.1135e-06\n",
            "Epoch 138/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 8.8582e-05 - mae: 4.0807e-07 - val_loss: 1.4715e-04 - val_mae: 5.8163e-06\n",
            "Epoch 139/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 8.5720e-05 - mae: 4.0897e-07 - val_loss: 1.4237e-04 - val_mae: 5.5130e-06\n",
            "Epoch 140/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 8.1528e-05 - mae: 3.0124e-07 - val_loss: 1.3838e-04 - val_mae: 5.4438e-06\n",
            "Epoch 141/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 7.8286e-05 - mae: 3.0266e-07 - val_loss: 1.3528e-04 - val_mae: 5.4313e-06\n",
            "Epoch 142/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 7.4837e-05 - mae: 2.7575e-07 - val_loss: 1.3072e-04 - val_mae: 5.0989e-06\n",
            "Epoch 143/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 7.1772e-05 - mae: 2.5173e-07 - val_loss: 1.2728e-04 - val_mae: 5.1149e-06\n",
            "Epoch 144/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 6.9088e-05 - mae: 2.4455e-07 - val_loss: 1.2217e-04 - val_mae: 4.6147e-06\n",
            "Epoch 145/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 6.6247e-05 - mae: 2.0870e-07 - val_loss: 1.1979e-04 - val_mae: 4.7297e-06\n",
            "Epoch 146/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 6.3341e-05 - mae: 1.9142e-07 - val_loss: 1.1692e-04 - val_mae: 4.6843e-06\n",
            "Epoch 147/150\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 6.0700e-05 - mae: 1.9563e-07 - val_loss: 1.1315e-04 - val_mae: 4.4579e-06\n",
            "Epoch 148/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 5.8064e-05 - mae: 1.6137e-07 - val_loss: 1.0952e-04 - val_mae: 4.2428e-06\n",
            "Epoch 149/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 5.5665e-05 - mae: 1.4362e-07 - val_loss: 1.0749e-04 - val_mae: 4.3113e-06\n",
            "Epoch 150/150\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 5.3466e-05 - mae: 1.4611e-07 - val_loss: 1.0438e-04 - val_mae: 4.1732e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRE8KpEqVfaS"
      },
      "source": [
        "### 3. Plot Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDsjqfjFm7Fz"
      },
      "source": [
        "**1. Mean Squared Error**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmvA-ksoln8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "8f345dff-9e83-49f7-fe3a-ae629fb877f5"
      },
      "source": [
        "# Draw a graph of the loss, which is the distance between\n",
        "# the predicted and actual values during training and validation.\n",
        "loss = history_1.history['loss']\n",
        "val_loss = history_1.history['val_loss']\n",
        "\n",
        "epochs = list(range(1, len(loss) + 1))\n",
        "\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(\n",
        "    go.Scatter(x = epochs, y = loss, name = \"Training loss\", mode = \"markers\")\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x = epochs, y = val_loss, name = \"Validation loss\", mode = \"markers\")\n",
        ")\n",
        "fig.update_layout(\n",
        "    xaxis = dict(title = \"Epochs\"),\n",
        "    yaxis = dict(title = \"Loss\"),\n",
        "    title = \"Training and Validation loss\"\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"7abded2a-57ed-4f5d-b56f-a403ae55859c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7abded2a-57ed-4f5d-b56f-a403ae55859c\")) {                    Plotly.newPlot(                        \"7abded2a-57ed-4f5d-b56f-a403ae55859c\",                        [{\"mode\":\"markers\",\"name\":\"Training loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150],\"y\":[0.6574158668518066,0.5375404953956604,0.4495468735694885,0.3740888833999634,0.3043578863143921,0.2431264966726303,0.19430118799209595,0.1579616516828537,0.13092420995235443,0.11061856895685196,0.09501166641712189,0.08257903158664703,0.07235290855169296,0.06387823075056076,0.05676999315619469,0.05074870213866234,0.045620061457157135,0.04119129851460457,0.03742685541510582,0.034141913056373596,0.03123638965189457,0.028704287484288216,0.026462489739060402,0.024411307647824287,0.022605253383517265,0.02096874639391899,0.019495539367198944,0.018165722489356995,0.01696452498435974,0.015866706147789955,0.014838937669992447,0.013916997238993645,0.013070029206573963,0.012286456301808357,0.011567634530365467,0.010917865671217442,0.010259692557156086,0.0096726194024086,0.00915800966322422,0.00864599458873272,0.008179206401109695,0.0077111017890274525,0.007303022779524326,0.006925731897354126,0.006543821655213833,0.00619553355500102,0.0058865174651145935,0.0055667925626039505,0.005280495621263981,0.004997985903173685,0.004740741569548845,0.004511660896241665,0.004263638518750668,0.0040641906671226025,0.003852935740724206,0.003659698646515608,0.0034756972454488277,0.0032956197392195463,0.0031472016125917435,0.002987016225233674,0.0028357692062854767,0.002701273187994957,0.0025754524394869804,0.002438491443172097,0.0023251730017364025,0.002221201080828905,0.0021011787466704845,0.0020019724033772945,0.001911807805299759,0.0018194415606558323,0.0017414619214832783,0.0016537518240511417,0.0015798384556546807,0.0015045498730614781,0.0014364602975547314,0.001373911160044372,0.0013159035006538033,0.0012510094093158841,0.0011912754271179438,0.0011406677076593041,0.00108640908729285,0.0010374535340815783,0.000992890214547515,0.0009481406887061894,0.0009063119068741798,0.000863483059220016,0.0008248306112363935,0.0007898936164565384,0.0007564934203401208,0.0007192430202849209,0.0006903772591613233,0.0006566083757206798,0.0006298469379544258,0.000602576183155179,0.0005742127541452646,0.0005495008663274348,0.0005242247716523707,0.0005026684957556427,0.0004799542366527021,0.0004595523059833795,0.00043921387987211347,0.00042062089778482914,0.00040196682675741613,0.0003868993080686778,0.00037009752122685313,0.00035169190960004926,0.00033755527692846954,0.0003233961760997772,0.00030892156064510345,0.0002961637219414115,0.00028411607490852475,0.0002712890272960067,0.00025955867022275925,0.0002490765182301402,0.00023821684590075165,0.0002280089829582721,0.0002192536776419729,0.0002099889243254438,0.000200829585082829,0.00019189702288713306,0.00018349048332311213,0.00017561500135343522,0.0001689678174443543,0.00016155299090314656,0.00015434915258083493,0.00014763709623366594,0.0001413584832334891,0.000135349779156968,0.00012977293226867914,0.000124658559798263,0.0001194351352751255,0.00011432386236265302,0.00010962453234242275,0.00010499860218260437,0.00010078930063173175,9.653558663558215e-05,9.258867794414982e-05,8.85816480149515e-05,8.572009392082691e-05,8.15283419797197e-05,7.828608067939058e-05,7.483650551876053e-05,7.177246880019084e-05,6.908763316459954e-05,6.624694651691243e-05,6.334136560326442e-05,6.070010567782447e-05,5.8064222685061395e-05,5.5664695537416264e-05,5.346575198927894e-05],\"type\":\"scatter\"},{\"mode\":\"markers\",\"name\":\"Validation loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150],\"y\":[0.5835403203964233,0.4858010709285736,0.4069593846797943,0.3363804519176483,0.27112090587615967,0.21702629327774048,0.1753360778093338,0.1444062888622284,0.12108379602432251,0.10336093604564667,0.08932781964540482,0.07786127179861069,0.0685233399271965,0.06067776679992676,0.05415836721658707,0.04859780892729759,0.043686676770448685,0.03943111002445221,0.03575986251235008,0.032527584582567215,0.029747679829597473,0.027250278741121292,0.025009676814079285,0.023040838539600372,0.021261289715766907,0.019671209156513214,0.018237607553601265,0.01695292256772518,0.015745125710964203,0.014662541449069977,0.013697217218577862,0.012812734581530094,0.01204890850931406,0.011311099864542484,0.010622912086546421,0.010009701363742352,0.009436513297259808,0.008905431255698204,0.008407821878790855,0.00799227599054575,0.00755189498886466,0.007186427712440491,0.0068114460445940495,0.006489155814051628,0.006132860202342272,0.005855528172105551,0.005589374806731939,0.0053087868727743626,0.005054759792983532,0.004869777709245682,0.004625726491212845,0.004430157598108053,0.004213589243590832,0.0039965203031897545,0.003803115338087082,0.00363064743578434,0.0034660068340599537,0.0032952907495200634,0.0031510498374700546,0.0030150669626891613,0.002877498045563698,0.002724692225456238,0.0026055986527353525,0.0024794926866889,0.002379935933277011,0.0022852816618978977,0.002176516456529498,0.002081235870718956,0.0019913630094379187,0.0019008066738024354,0.0018257967894896865,0.0017457458889111876,0.0016687785973772407,0.0016018747119233012,0.0015353703638538718,0.00147208571434021,0.0014070651959627867,0.001347083249129355,0.0013012309791520238,0.001238061930052936,0.0011830911971628666,0.00114021438639611,0.0010888538090512156,0.0010455488227307796,0.0010022191563621163,0.0009611602872610092,0.0009236192563548684,0.0008812801679596305,0.0008436659700237215,0.0008115463424474001,0.0007805076311342418,0.0007535589393228292,0.0007211373304016888,0.0006931698881089687,0.0006673707393929362,0.0006414942326955497,0.0006166116218082607,0.0005909563624300063,0.0005697858287021518,0.0005492698401212692,0.0005291231209412217,0.0005122743314132094,0.0004896448226645589,0.0004794535634573549,0.00045461044646799564,0.0004398938035592437,0.0004235684755258262,0.0004075117758475244,0.0003937453730031848,0.00037864630576223135,0.0003676170890685171,0.0003528271336108446,0.0003417992265895009,0.000328599737258628,0.0003177705511916429,0.0003090450190939009,0.00029820698546245694,0.0002849537122529,0.00027306503034196794,0.000267556170001626,0.00025737975374795496,0.00024686564574949443,0.00023853167658671737,0.00022891424305271357,0.00022390153026208282,0.0002184096083510667,0.0002110192144755274,0.00020683821639977396,0.00019872633856721222,0.0001926280529005453,0.00018699980864766985,0.00018089950026478618,0.00017226081399712712,0.0001683609007159248,0.00016539260104764253,0.00015600510232616216,0.000152937849634327,0.0001471498399041593,0.00014236578135751188,0.00013838254380971193,0.00013528238923754543,0.0001307192287640646,0.00012727524153888226,0.00012216862523928285,0.00011979028931818902,0.00011692300176946446,0.00011314715084154159,0.00010951729927910492,0.00010748981731012464,0.00010438208119012415],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"title\":{\"text\":\"Training and Validation loss\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7abded2a-57ed-4f5d-b56f-a403ae55859c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOFBSbPcYCN4"
      },
      "source": [
        "\n",
        "As we can see, the amount of loss rapidly decreases over the first 20 epochs, before flattening out. This means that the model is improving and producing more accurate predictions!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md9E_azmpkZU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "fe00ba4a-22b2-4050-e7e9-c570f91179f9"
      },
      "source": [
        "# Draw a graph of mean absolute error, which is another way of\n",
        "# measuring the amount of error in the prediction.\n",
        "mae = history_1.history['mae']\n",
        "val_mae = history_1.history['val_mae']\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(\n",
        "    go.Scatter(x = epochs, y= mae, name = \"Training MAE\", mode = \"markers\")\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x = epochs, y= val_mae, name = \"Validation MAE\", mode = \"markers\")\n",
        ")\n",
        "fig.update_layout(\n",
        "    xaxis = dict(title = \"Epochs\"),\n",
        "    yaxis = dict(title = \"MAE\"),\n",
        "    title = \"Training and validation mean absolute error\"\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"efe86a62-12d7-456e-828d-eb2ff771b2a7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"efe86a62-12d7-456e-828d-eb2ff771b2a7\")) {                    Plotly.newPlot(                        \"efe86a62-12d7-456e-828d-eb2ff771b2a7\",                        [{\"mode\":\"markers\",\"name\":\"Training MAE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150],\"y\":[0.44998759031295776,0.3431206941604614,0.2704015374183655,0.20700480043888092,0.14709408581256866,0.09878137707710266,0.06692750751972198,0.048118263483047485,0.03680196776986122,0.029459021985530853,0.02462606132030487,0.020764067769050598,0.017987702041864395,0.01543187815696001,0.013616095297038555,0.012109355069696903,0.010702154599130154,0.00939891953021288,0.008647017180919647,0.007639938499778509,0.007007226347923279,0.006288600154221058,0.005862034857273102,0.005385980941355228,0.0049357665702700615,0.004483092110604048,0.00408775731921196,0.003801898332312703,0.0036174494307488203,0.00318447919562459,0.003000963246449828,0.0028084616642445326,0.0025415951386094093,0.002408117288723588,0.0021952278912067413,0.0021164624486118555,0.0019147087587043643,0.0017998878611251712,0.0017474553314968944,0.001612225198186934,0.0015063716564327478,0.0013780781300738454,0.0013328049099072814,0.001297460519708693,0.0012019150890409946,0.0011092268396168947,0.0010779498843476176,0.00099812017288059,0.0009506113128736615,0.0007841334445402026,0.0008082674467004836,0.0007390598766505718,0.0006688141729682684,0.0006568307871930301,0.0006020630244165659,0.0005551513750106096,0.0005131507641635835,0.0004497129120863974,0.0004076159093528986,0.00040510325925424695,0.0003613292647060007,0.00029369836556725204,0.0003224666288588196,0.00026704155607149005,0.0002486888552084565,0.00021303097310010344,0.00019306078320369124,0.0001845665101427585,0.00016947300173342228,0.00014724874927196652,0.00013883537030778825,0.00013446695811580867,0.00011693932174239308,0.00010213606583420187,9.899050928652287e-05,9.645169484429061e-05,7.983811519807205e-05,8.340100612258539e-05,6.988473614910617e-05,6.541432230733335e-05,5.492630953085609e-05,5.298636824591085e-05,4.938970596413128e-05,4.360850653029047e-05,4.145556522416882e-05,3.692219252116047e-05,3.4726501326076686e-05,3.1612085876986384e-05,2.982511796290055e-05,2.4273784219985828e-05,2.5660765459178947e-05,2.0738392777275294e-05,1.9919823898817413e-05,1.9387358406675048e-05,1.6309786587953568e-05,1.5429972336278297e-05,1.3512751138478052e-05,1.3663835488841869e-05,1.0460745215823408e-05,1.0663702596502844e-05,9.636486538511235e-06,8.720880032342393e-06,7.996232852747198e-06,8.675780009070877e-06,7.035755061224336e-06,5.723535196011653e-06,6.25851544100442e-06,5.062770924268989e-06,4.3878440010303166e-06,4.541045655059861e-06,4.649430138670141e-06,3.6579256175173214e-06,3.3392013847333146e-06,3.3880323826451786e-06,2.6101197363459505e-06,2.6961693038174417e-06,2.4781945739960065e-06,2.357126504648477e-06,2.2445105969381984e-06,1.8338539575779578e-06,1.5957964478729991e-06,1.3547429489335627e-06,1.5895569731583237e-06,1.348858859273605e-06,9.559952331983368e-07,1.008792764878308e-06,9.821468438531156e-07,8.464278380415635e-07,7.876085419411538e-07,8.412068268626172e-07,6.82832080656226e-07,6.450348450925958e-07,6.002966301821289e-07,4.904675847683393e-07,5.060659304945148e-07,4.505191384396312e-07,4.2629110907910217e-07,4.0807077539284364e-07,4.0897108988247055e-07,3.012363833931886e-07,3.026590604804369e-07,2.757500396910473e-07,2.517251971312362e-07,2.445542293116887e-07,2.086993760030964e-07,1.914174276862468e-07,1.9563194086913427e-07,1.6137363445523079e-07,1.4361894784542528e-07,1.461129102153791e-07],\"type\":\"scatter\"},{\"mode\":\"markers\",\"name\":\"Validation MAE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150],\"y\":[0.3837272822856903,0.30080288648605347,0.2362401783466339,0.17590396106243134,0.12103445082902908,0.08211660385131836,0.0579700767993927,0.043462324887514114,0.0342387892305851,0.028202487155795097,0.023431656882166862,0.019752686843276024,0.01679414138197899,0.014534915797412395,0.012659389525651932,0.011060577817261219,0.00957661122083664,0.008570019155740738,0.007533542346209288,0.006749237421900034,0.0061800493858754635,0.005732469726353884,0.005144430324435234,0.0047665671445429325,0.004330523312091827,0.003940307069569826,0.0036862343549728394,0.003455488011240959,0.0031238077208399773,0.0028492261189967394,0.002627319423481822,0.0024437750689685345,0.0022373769897967577,0.0020537972450256348,0.001955983694642782,0.0018139826133847237,0.0016520997742190957,0.0015860942658036947,0.0015100287273526192,0.001374808605760336,0.0013090426800772548,0.0012361503904685378,0.0011853809701278806,0.0011417327914386988,0.0010720057180151343,0.0010038823820650578,0.0009595972951501608,0.000898278784006834,0.0008709393441677094,0.0007797601283527911,0.0007556635537184775,0.0007194994832389057,0.0007033443544059992,0.000663904647808522,0.0006327838636934757,0.000582377309910953,0.0005329363630153239,0.0005114177474752069,0.0004891855642199516,0.0004533483588602394,0.0004264312738087028,0.0003551870468072593,0.0003643580130301416,0.00030971295200288296,0.00031545275123789907,0.00027919645071960986,0.0002700194308999926,0.0002503128780517727,0.00023573209182359278,0.00022529924171976745,0.00020481122191995382,0.0001946776610566303,0.00017146047321148217,0.00017169663624372333,0.0001610610488569364,0.00015554140554741025,0.00013679868425242603,0.00012461301230359823,0.00012793739733751863,0.00011026103311451152,0.00010117117199115455,9.762182889971882e-05,8.647431241115555e-05,8.181772864190862e-05,7.633596396772191e-05,7.320665463339537e-05,6.965327338548377e-05,6.239542562980205e-05,5.615695408778265e-05,5.523944855667651e-05,5.1190010708523914e-05,5.0457594625186175e-05,4.629550676327199e-05,4.461081698536873e-05,3.7461886677192524e-05,3.6462413845583797e-05,3.5486100387061015e-05,3.250402369303629e-05,3.1569925340591e-05,3.162126449751668e-05,2.8969747290830128e-05,2.9121672923793085e-05,2.623229920573067e-05,2.8442016628105193e-05,2.294533624080941e-05,2.2769778297515586e-05,2.1648493202519603e-05,2.021477121161297e-05,2.0072689949302003e-05,1.8746179193840362e-05,1.856889321061317e-05,1.7547819879837334e-05,1.693242484179791e-05,1.5563562556053512e-05,1.5122211152629461e-05,1.5358276868937537e-05,1.4351003301271703e-05,1.283022720599547e-05,1.1612379239522852e-05,1.202242674480658e-05,1.1602526683418546e-05,1.0121470950252842e-05,9.866486834653188e-06,9.038215466716792e-06,9.134012543654535e-06,9.23185234569246e-06,8.936931408243254e-06,9.534464879834559e-06,8.763680853007827e-06,8.31398483569501e-06,8.183325917343609e-06,7.85970132710645e-06,7.088764050422469e-06,7.098057722032536e-06,7.425106105074519e-06,5.901143140363274e-06,6.1134674069762696e-06,5.8163050198345445e-06,5.513035830517765e-06,5.443783720693318e-06,5.43129317520652e-06,5.098898782307515e-06,5.114887699164683e-06,4.6146697059157304e-06,4.729680313175777e-06,4.684288342104992e-06,4.457865998119814e-06,4.242783234076342e-06,4.311261818656931e-06,4.173157321929466e-06],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"MAE\"}},\"title\":{\"text\":\"Training and validation mean absolute error\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('efe86a62-12d7-456e-828d-eb2ff771b2a7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i13eVIT3B9Mj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "a1080188-099f-4abb-f2f0-856e74bb5f9e"
      },
      "source": [
        "# Use the model to make predictions from our validation data\n",
        "predictions = model_1.predict(x_test)\n",
        "\n",
        "correct = [0, 0]\n",
        "wrong = [0, 0]\n",
        "\n",
        "for i in range(predictions.shape[0]):\n",
        "    p = np.argmax(predictions[i])\n",
        "    a = np.argmax(y_test[i])\n",
        "\n",
        "    if p == a:\n",
        "        correct[a] += 1\n",
        "    else:\n",
        "        wrong[a] += 1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "species = ['No Tap', 'Tap']\n",
        "weight_counts = {\n",
        "    \"Right\": correct,\n",
        "    \"wrong\": wrong,\n",
        "}\n",
        "width = 0.5\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bottom = np.zeros(2)\n",
        "\n",
        "for boolean, weight_count in weight_counts.items():\n",
        "    p = ax.bar(species, weight_count, width, label=boolean, bottom=bottom)\n",
        "    bottom += weight_count\n",
        "plt.title(\"Classification Accuracy\")\n",
        "plt.ylabel(\"Test Samples\")\n",
        "plt.legend([\"Correct Classification\", \"Incorrect Classification\"])\n",
        "plt.show()\n",
        "\n",
        "total = sum(weight_counts[\"Right\"]) + sum(weight_counts[\"wrong\"])\n",
        "\n",
        "print(sum(weight_counts[\"Right\"])/total)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h7IcvuOOS4J"
      },
      "source": [
        "## Generate a TensorFlow Lite Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHe-Wv47rhm8"
      },
      "source": [
        "### 1. Generate Models with or without Quantization\n",
        "We now have an acceptably accurate model. We'll use the [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert) to convert the model into a special, space-efficient format for use on memory-constrained devices.\n",
        "\n",
        "In the following cell, we'll convert the model twice: once with quantization, once without."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1muAoUm8lSXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b62f032-8af5-4feb-9b06-a5a2fef2445c"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_1)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "\n",
        "# # Save the model to disk\n",
        "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
        "\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "def representative_dataset():\n",
        "  for i in range(x_train.shape[0]):\n",
        "    yield([x_train[i].astype(np.float32)])\n",
        "\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Enforce full-int8 quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# Provide a representative dataset to ensure we quantize correctly.\n",
        "converter.representative_dataset = representative_dataset\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:789: UserWarning:\n",
            "\n",
            "Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2264"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X1yO3h5pYbt"
      },
      "source": [
        "### 2. Compare Model Sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAIe0dK3pXU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8d95e2-0a55-43f9-cae3-2ebb47c9d6a4"
      },
      "source": [
        "import sys, os\n",
        "def format_size(variable):\n",
        "    size_in_bytes = sys.getsizeof(variable)\n",
        "    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n",
        "    unit_index = 0\n",
        "    while size_in_bytes >= 1024 and unit_index < len(units) - 1:\n",
        "        size_in_bytes /= 1024.0\n",
        "        unit_index += 1\n",
        "    return \"{:.2f} {}\".format(size_in_bytes, units[unit_index])\n",
        "\n",
        "print(\"Model is {}\".format(format_size(model_no_quant_tflite)))\n",
        "print(\"Quantized Model is {}\".format(format_size(model_tflite)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 2.46 KB\n",
            "Quantized Model is 2.24 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR2OuokFpkEM"
      },
      "source": [
        "Our quantized model is only 0.22 kilobytes smaller than the original version, which only a tiny reduction in size! Because the difference is so small, we will use the unquantized version in our arduino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vE-ZDkHVxe"
      },
      "source": [
        "### 3. Test the Models\n",
        "\n",
        "To prove these models are still accurate after conversion and quantization, we'll use both of them to make predictions and compare these against our test results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPSFmDL7pv2L"
      },
      "source": [
        "## Generate a TensorFlow Lite for Microcontrollers Model\n",
        "Convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1FB4ieeg0lw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bafbd29-5dc4-41e8-d6c7-4c0846f3cf61"
      },
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "# Convert to a C source file\n",
        "!xxd -i {MODEL_NO_QUANT_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "# Update variable names\n",
        "REPLACE_TEXT = MODEL_NO_QUANT_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvRy0ZyMhQOX"
      },
      "source": [
        "## Deploy to a Microcontroller\n",
        "\n",
        "Follow the instructions in the [hello_world](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world) README.md for [TensorFlow Lite for MicroControllers](https://www.tensorflow.org/lite/microcontrollers/overview) to deploy this model on a specific microcontroller.\n",
        "\n",
        "**Reference Model:** If you have not modified this notebook, you can follow the instructions as is, to deploy the model. Refer to the [`hello_world/train/models`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/models) directory to access the models generated in this notebook.\n",
        "\n",
        "**New Model:** If you have generated a new model, then update the values assigned to the variables defined in [`hello_world/model.cc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/model.cc) with values displayed after running the following cell.\n",
        "\n",
        "**Errors:** Type should match; otherwise, there will be an error. In your model.ccp and model.h files, make sure that the type matches. If it's declared as \"const unsigned char g_model[]\" make sure that it is the same in both places. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-WhtGpvb-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3b9c55-38a0-4463-d940-e9bc58da59bb"
      },
      "source": [
        "# Print the C source file\n",
        "!cat {MODEL_TFLITE_MICRO}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unsigned char g_model[] = {\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x14, 0x00, 0x20, 0x00,\n",
            "  0x1c, 0x00, 0x18, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x98, 0x00, 0x00, 0x00, 0xf0, 0x00, 0x00, 0x00, 0xc4, 0x04, 0x00, 0x00,\n",
            "  0xd4, 0x04, 0x00, 0x00, 0x54, 0x09, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00,\n",
            "  0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\n",
            "  0x0f, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76, 0x69, 0x6e, 0x67, 0x5f,\n",
            "  0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x90, 0xff, 0xff, 0xff, 0x07, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x64, 0x65, 0x6e, 0x73,\n",
            "  0x65, 0x5f, 0x31, 0x37, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x26, 0xfb, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31, 0x36,\n",
            "  0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x34, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xdc, 0xff, 0xff, 0xff,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n",
            "  0x43, 0x4f, 0x4e, 0x56, 0x45, 0x52, 0x53, 0x49, 0x4f, 0x4e, 0x5f, 0x4d,\n",
            "  0x45, 0x54, 0x41, 0x44, 0x41, 0x54, 0x41, 0x00, 0x08, 0x00, 0x0c, 0x00,\n",
            "  0x08, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00, 0x6d, 0x69, 0x6e, 0x5f,\n",
            "  0x72, 0x75, 0x6e, 0x74, 0x69, 0x6d, 0x65, 0x5f, 0x76, 0x65, 0x72, 0x73,\n",
            "  0x69, 0x6f, 0x6e, 0x00, 0x0b, 0x00, 0x00, 0x00, 0xd0, 0x03, 0x00, 0x00,\n",
            "  0xc8, 0x03, 0x00, 0x00, 0xb0, 0x03, 0x00, 0x00, 0x80, 0x03, 0x00, 0x00,\n",
            "  0xf0, 0x00, 0x00, 0x00, 0xa0, 0x00, 0x00, 0x00, 0x98, 0x00, 0x00, 0x00,\n",
            "  0x90, 0x00, 0x00, 0x00, 0x88, 0x00, 0x00, 0x00, 0x68, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0xce, 0xfb, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x54, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0e, 0x00,\n",
            "  0x08, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x0a, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00, 0x32, 0x2e, 0x31, 0x32,\n",
            "  0x2e, 0x30, 0x00, 0x00, 0x2e, 0xfc, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x31, 0x2e, 0x35, 0x2e, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x78, 0xf8, 0xff, 0xff,\n",
            "  0x7c, 0xf8, 0xff, 0xff, 0x80, 0xf8, 0xff, 0xff, 0x56, 0xfc, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0xee, 0x41, 0x1c, 0x40,\n",
            "  0x18, 0x37, 0xf9, 0xbf, 0x09, 0x07, 0x0e, 0xc0, 0xa6, 0x57, 0x3c, 0xc0,\n",
            "  0xfa, 0xab, 0x11, 0xc0, 0xfd, 0x1b, 0x1f, 0xc0, 0xfd, 0x72, 0x23, 0xc0,\n",
            "  0xc2, 0x5d, 0x9e, 0xbe, 0x8d, 0x95, 0x0e, 0xc0, 0x95, 0x16, 0x13, 0x40,\n",
            "  0x19, 0xaf, 0xf4, 0x3f, 0x2b, 0xea, 0x37, 0x40, 0x73, 0xaa, 0x19, 0x40,\n",
            "  0x5d, 0xc0, 0x04, 0x40, 0x6d, 0xf7, 0xf1, 0x3f, 0x99, 0xc0, 0x97, 0xbc,\n",
            "  0xa2, 0xfc, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x80, 0x02, 0x00, 0x00,\n",
            "  0x88, 0x5c, 0x92, 0xbf, 0x45, 0x73, 0xa7, 0xbf, 0x95, 0x74, 0x8f, 0x3f,\n",
            "  0x3e, 0x5f, 0xbb, 0x3e, 0x34, 0xa5, 0xf5, 0xbd, 0x82, 0xdc, 0x6d, 0xbf,\n",
            "  0x9b, 0x7a, 0x62, 0x3d, 0x38, 0xbc, 0x6a, 0x3f, 0x3d, 0x68, 0xac, 0xbe,\n",
            "  0x2a, 0xa4, 0xf7, 0xbd, 0xaf, 0x7b, 0xd1, 0xbe, 0x8a, 0xf7, 0x87, 0xbd,\n",
            "  0xc2, 0x3b, 0xb1, 0xbe, 0xbc, 0xe0, 0xed, 0xbd, 0x83, 0x46, 0x40, 0xbd,\n",
            "  0x99, 0x15, 0xaa, 0xbe, 0xe8, 0xd3, 0xde, 0xbd, 0xd7, 0x7e, 0x8f, 0xbf,\n",
            "  0x11, 0xbb, 0xf4, 0xbf, 0x36, 0xfd, 0x0f, 0xc0, 0xe6, 0x57, 0x90, 0xbf,\n",
            "  0xdc, 0x55, 0xfb, 0xbe, 0xe9, 0xfd, 0x7c, 0x3f, 0x56, 0x44, 0x6e, 0x3f,\n",
            "  0xb0, 0x59, 0x1c, 0xbd, 0x55, 0xdc, 0xb6, 0xbf, 0x83, 0x31, 0x00, 0xbf,\n",
            "  0x68, 0x5c, 0x81, 0x3f, 0xe1, 0xf0, 0x13, 0xbf, 0xcb, 0x04, 0x78, 0xbf,\n",
            "  0x9c, 0x00, 0xc2, 0x3e, 0xfa, 0xf8, 0x84, 0x3f, 0x71, 0x47, 0xf1, 0x3d,\n",
            "  0x1e, 0xe0, 0x22, 0xbf, 0xb4, 0x1b, 0x35, 0x3f, 0x86, 0xce, 0xa3, 0x3f,\n",
            "  0x4d, 0x37, 0xae, 0xbf, 0xd7, 0x28, 0x01, 0xbf, 0xaa, 0x90, 0x95, 0x3f,\n",
            "  0x62, 0x26, 0x1e, 0x40, 0xdf, 0xc1, 0x13, 0x3f, 0x10, 0x31, 0x92, 0x3f,\n",
            "  0x01, 0x7e, 0x6a, 0xbe, 0x8b, 0x7d, 0x68, 0xbf, 0xa0, 0x63, 0x28, 0x3f,\n",
            "  0x87, 0xcc, 0xdd, 0x3d, 0x6e, 0xc7, 0x24, 0xbf, 0x17, 0x31, 0xf6, 0xbe,\n",
            "  0x41, 0x64, 0x69, 0x3e, 0xeb, 0x27, 0xb8, 0x3f, 0xdf, 0x5b, 0xb5, 0x3f,\n",
            "  0x3c, 0xdc, 0x83, 0xbf, 0x8c, 0xf0, 0x4d, 0xbf, 0xd4, 0x97, 0xa7, 0x3f,\n",
            "  0xa2, 0xa3, 0x2f, 0x3f, 0x44, 0x68, 0x33, 0xbf, 0x85, 0x6d, 0x48, 0x3e,\n",
            "  0x09, 0x94, 0x06, 0xbf, 0x8f, 0x7b, 0xf5, 0x3f, 0xbe, 0x21, 0x80, 0xbf,\n",
            "  0x34, 0xbe, 0x5f, 0x3f, 0xff, 0x6f, 0x52, 0x3c, 0xea, 0x0a, 0x59, 0x3f,\n",
            "  0xa5, 0x47, 0x73, 0xbf, 0xb0, 0x7f, 0x83, 0xbf, 0xaf, 0xf4, 0xe5, 0x3d,\n",
            "  0x7e, 0x8f, 0xa8, 0x3e, 0xfb, 0xb3, 0x24, 0x3f, 0xab, 0xb1, 0x21, 0x3f,\n",
            "  0x1c, 0x2f, 0xbe, 0xbf, 0xdb, 0xc2, 0xb3, 0xbe, 0x49, 0x0b, 0xe7, 0x3e,\n",
            "  0xa7, 0x9d, 0x2a, 0x3f, 0x83, 0x51, 0xa8, 0x3f, 0xef, 0xd9, 0x8b, 0xbf,\n",
            "  0x1d, 0x74, 0xa7, 0xbe, 0x1c, 0xce, 0xae, 0x3f, 0x94, 0xf6, 0xba, 0xbf,\n",
            "  0x1c, 0x09, 0x58, 0xbe, 0x23, 0x9d, 0xb7, 0x3f, 0xcd, 0xf5, 0x06, 0x3f,\n",
            "  0xba, 0x54, 0xb8, 0x3f, 0x71, 0x02, 0x21, 0x3f, 0x16, 0x7b, 0x87, 0xbf,\n",
            "  0x2c, 0x7a, 0x00, 0xc0, 0x20, 0xb0, 0x89, 0x3f, 0xf4, 0x00, 0x9e, 0x3f,\n",
            "  0xd2, 0xec, 0x04, 0xbf, 0x62, 0xf2, 0x7b, 0x3c, 0x3a, 0x0a, 0xc9, 0x3e,\n",
            "  0x69, 0xeb, 0x37, 0xbf, 0xf5, 0x40, 0x00, 0x3d, 0x32, 0x5d, 0x11, 0xbf,\n",
            "  0xc6, 0x24, 0x0b, 0x3f, 0x7a, 0x6c, 0x5d, 0x3f, 0x07, 0x09, 0x01, 0xc0,\n",
            "  0x5f, 0x20, 0x6c, 0xbf, 0x7b, 0x47, 0x28, 0x40, 0x2f, 0x36, 0xee, 0x3f,\n",
            "  0xe2, 0xe5, 0x4e, 0xbf, 0xbe, 0x75, 0x3a, 0x3f, 0x95, 0x4c, 0xdb, 0x3e,\n",
            "  0x4f, 0xb5, 0xb6, 0xbf, 0xd5, 0x85, 0xf5, 0x3d, 0x86, 0x5c, 0x47, 0x3f,\n",
            "  0xd4, 0xe6, 0x40, 0x3e, 0x77, 0x95, 0xca, 0xbf, 0x12, 0xdf, 0x2e, 0xbf,\n",
            "  0xe5, 0xba, 0x27, 0x3f, 0x0f, 0x4c, 0x16, 0x3e, 0x70, 0xf6, 0xdd, 0xbf,\n",
            "  0xf0, 0x03, 0xc9, 0x3e, 0x20, 0x49, 0xee, 0x3f, 0x60, 0x84, 0xd8, 0xbd,\n",
            "  0x4f, 0xaf, 0x23, 0xbf, 0x66, 0x1e, 0xd0, 0x3d, 0x20, 0x82, 0xb4, 0x3f,\n",
            "  0x1d, 0xd5, 0x56, 0xbd, 0x10, 0xc1, 0x12, 0x3f, 0x8d, 0x45, 0x0d, 0x40,\n",
            "  0x95, 0x88, 0x62, 0xbf, 0xb5, 0x22, 0xf8, 0xbe, 0x7d, 0x39, 0xb3, 0x3f,\n",
            "  0x4c, 0x12, 0xbe, 0x3d, 0x28, 0x0d, 0xf3, 0xbe, 0x84, 0x56, 0xa2, 0xbf,\n",
            "  0xdd, 0xfe, 0x2a, 0x3f, 0x5c, 0x60, 0x4c, 0x3f, 0xb1, 0xa5, 0x56, 0xbf,\n",
            "  0xd7, 0xf7, 0xaf, 0xbf, 0xbb, 0xf3, 0xce, 0x3e, 0x49, 0x2b, 0xaa, 0x3e,\n",
            "  0x52, 0xe1, 0x47, 0xbe, 0xc8, 0x62, 0xc7, 0xbf, 0x55, 0xe8, 0x8c, 0x3f,\n",
            "  0xad, 0x71, 0x59, 0x3f, 0xa9, 0xb9, 0xe7, 0xbe, 0x6a, 0xf2, 0xf7, 0x3f,\n",
            "  0x5d, 0x7c, 0x0e, 0x3f, 0xed, 0x2b, 0x64, 0x3f, 0x84, 0xa4, 0x6f, 0x3d,\n",
            "  0x24, 0x8e, 0x5e, 0x3e, 0x56, 0x1b, 0x82, 0x3e, 0xd4, 0x10, 0xa9, 0x3e,\n",
            "  0xc6, 0x99, 0x3e, 0xbe, 0xc5, 0x8b, 0x8a, 0x3e, 0x18, 0x9e, 0x1a, 0xbc,\n",
            "  0xbd, 0xf3, 0xda, 0x3e, 0xde, 0x01, 0x65, 0xbd, 0x49, 0x72, 0xe7, 0xbd,\n",
            "  0xcf, 0x12, 0x43, 0x3d, 0xf3, 0xec, 0x4f, 0x3e, 0x50, 0xf1, 0x96, 0x3d,\n",
            "  0x83, 0x7f, 0x84, 0xbc, 0xc6, 0x0e, 0x8c, 0x3e, 0xe4, 0x5f, 0xf1, 0xbd,\n",
            "  0xb6, 0x22, 0xad, 0xbd, 0xb6, 0xd7, 0x0c, 0xbe, 0xd8, 0xf8, 0x0f, 0x3e,\n",
            "  0x0b, 0x09, 0xdf, 0xbd, 0x2e, 0xff, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0xdf, 0x8e, 0x0a, 0x40, 0xde, 0xf8, 0xdf, 0x3e,\n",
            "  0xa7, 0xe1, 0x57, 0x3f, 0xeb, 0xc5, 0x8f, 0xbe, 0xe2, 0xb8, 0xfb, 0x3e,\n",
            "  0x84, 0x65, 0xe4, 0x3e, 0xed, 0x1e, 0xe7, 0xbe, 0x26, 0x4d, 0x0d, 0xbe,\n",
            "  0x5a, 0xff, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x99, 0x2e, 0x97, 0x3f, 0xf9, 0x7e, 0xb2, 0xbf, 0x9c, 0xfb, 0xff, 0xff,\n",
            "  0xa0, 0xfb, 0xff, 0xff, 0x0f, 0x00, 0x00, 0x00, 0x4d, 0x4c, 0x49, 0x52,\n",
            "  0x20, 0x43, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x18, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0xec, 0x00, 0x00, 0x00, 0xf0, 0x00, 0x00, 0x00, 0xf4, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x6d, 0x61, 0x69, 0x6e, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x94, 0x00, 0x00, 0x00, 0x50, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x1a, 0x00, 0x14, 0x00,\n",
            "  0x10, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00,\n",
            "  0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x3f,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0xce, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x08, 0x0c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x60, 0xfc, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x16, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x07, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x05, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x07, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0xfc, 0x02, 0x00, 0x00, 0x88, 0x02, 0x00, 0x00,\n",
            "  0x14, 0x02, 0x00, 0x00, 0xc4, 0x01, 0x00, 0x00, 0x74, 0x01, 0x00, 0x00,\n",
            "  0xdc, 0x00, 0x00, 0x00, 0x60, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x3a, 0xfd, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x34, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x24, 0xfd, 0xff, 0xff, 0x19, 0x00, 0x00, 0x00,\n",
            "  0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74,\n",
            "  0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x3a,\n",
            "  0x30, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x92, 0xfd, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x07, 0x00, 0x00, 0x00, 0x54, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x02, 0x00, 0x00, 0x00, 0x7c, 0xfd, 0xff, 0xff,\n",
            "  0x3a, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x38, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31,\n",
            "  0x37, 0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x73, 0x65, 0x71,\n",
            "  0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x38, 0x2f, 0x64, 0x65,\n",
            "  0x6e, 0x73, 0x65, 0x5f, 0x31, 0x37, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41,\n",
            "  0x64, 0x64, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x0a, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x70, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0xf4, 0xfd, 0xff, 0xff,\n",
            "  0x55, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x38, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31,\n",
            "  0x36, 0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x73, 0x65, 0x71,\n",
            "  0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x38, 0x2f, 0x64, 0x65,\n",
            "  0x6e, 0x73, 0x65, 0x5f, 0x31, 0x36, 0x2f, 0x52, 0x65, 0x6c, 0x75, 0x3b,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x38,\n",
            "  0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31, 0x36, 0x2f, 0x42, 0x69,\n",
            "  0x61, 0x73, 0x41, 0x64, 0x64, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x0e, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x01, 0x10, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x05, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00, 0x78, 0xfe, 0xff, 0xff,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x38, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31,\n",
            "  0x37, 0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x5a, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00,\n",
            "  0xc4, 0xfe, 0xff, 0xff, 0x1c, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
            "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x38, 0x2f, 0x64, 0x65, 0x6e,\n",
            "  0x73, 0x65, 0x5f, 0x31, 0x36, 0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0xa6, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x3c, 0x00, 0x00, 0x00, 0x10, 0xff, 0xff, 0xff, 0x2c, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x38,\n",
            "  0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31, 0x36, 0x2f, 0x42, 0x69,\n",
            "  0x61, 0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65, 0x61, 0x64, 0x56, 0x61,\n",
            "  0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x16, 0x00,\n",
            "  0x18, 0x00, 0x14, 0x00, 0x00, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x07, 0x00, 0x16, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x01, 0x10, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff,\n",
            "  0x2c, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x5f, 0x38, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31,\n",
            "  0x37, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65,\n",
            "  0x61, 0x64, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x16, 0x00, 0x1c, 0x00, 0x18, 0x00, 0x00, 0x00, 0x14, 0x00,\n",
            "  0x10, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x00, 0x07, 0x00,\n",
            "  0x16, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x40, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x04, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76, 0x69, 0x6e, 0x67, 0x5f,\n",
            "  0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x5f, 0x64, 0x65, 0x6e, 0x73,\n",
            "  0x65, 0x5f, 0x31, 0x36, 0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x3a, 0x30,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0xf4, 0xff, 0xff, 0xff, 0x19, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x19, 0x0c, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x09\n",
            "};\n",
            "unsigned int g_model_len = 2488;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KAhSI1x5QEbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}